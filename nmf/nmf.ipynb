{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Resources Used: https://predictivehacks.com/topic-modelling-with-nmf-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique topic words on testing data ['kindle2' 'aig' 'jquery' 'twitter' 'obama' 'nike' 'lebron' 'iphone app'\n",
      " 'visa' 'fredwilson' '\"booz allen\"' '40d' 'google' 'itchy' 'stanford'\n",
      " 'lyx' 'Danny Gokey' 'sleep' 'san francisco' 'star trek'\n",
      " 'Malcolm Gladwell' 'espn' '\"twitter api\"' 'yahoo' 'scrapbooking'\n",
      " 'wolfram alpha' 'weka' '50d' 'lambda calculus' 'east palo alto' 'lakers'\n",
      " 'north korea' 'pelosi' 'bailout' 'insects' 'mcdonalds' 'exam' 'cheney'\n",
      " 'republican' 'twitter api' 'jquery book' 'goodby silverstein' 'wieden'\n",
      " 'g2' 'googleio' 'viral marketing' '\"night at the museum\"' 'gm'\n",
      " 'time warner' 'china' 'surgery' 'dentist' 'baseball' 'sony' 'safeway'\n",
      " 'eating' 'warren buffet' 'notre dame school' 'federer' '\"naive bayes\"'\n",
      " 'car warranty call' 'at&t' 'wave sandbox' 'bing' 'summize' 'world cup'\n",
      " 'world cup 2010' 'fred wilson' 'indian election' 'india election'\n",
      " 'comcast' 'shoreline amphitheatre' 'mashable' 'hitler' 'yankees'\n",
      " 'driving' 'visa card' 'Bobby Flay' 'latex' 'iran' 'aapl']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/test_data.csv')\n",
    "print('unique topic words on testing data', df.kindle2.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_at(text):\n",
    "    # A username can only contain alphanumeric characters (letters A-Z, numbers 0-9) with the exception of underscores,\n",
    "    # as noted above. Check to make sure your desired username doesn't contain any symbols, dashes, or spaces.\n",
    "    pattern = r'@([A-Za-z0-9_])+'\n",
    "    # Replace all occurrences of @username with an empty string\n",
    "    # https://towardsdatascience.com/topic-modeling-and-sentiment-analysis-on-twitter-data-using-spark-a145bfcc433\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = r'http\\S+'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = r'bit.ly/\\S+'\n",
    "    # replace all links with empty string\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = r'#([A-Za-z]+[A-Za-z0-9-_]+)'\n",
    "    # replace all hashtags with empty string\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Polarity', 'ID', 'Date', 'Topic', 'User', 'Text']\n",
    "df['Text'] = df['Text'].apply(remove_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the  ...it fucking rock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>You'll love your Kindle2. I've had mine for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>Fair enough. But i have the Kindle2 and I th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>no. it is too big. I'm quite happy with the K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity  ID                          Date    Topic          User  \\\n",
       "0         4   4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
       "1         4   5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
       "2         4   6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
       "3         4   7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
       "4         4   8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
       "\n",
       "                                                Text  \n",
       "0  Reading my kindle2...  Love it... Lee childs i...  \n",
       "1  Ok, first assesment of the  ...it fucking rock...  \n",
       "2   You'll love your Kindle2. I've had mine for a...  \n",
       "3    Fair enough. But i have the Kindle2 and I th...  \n",
       "4   no. it is too big. I'm quite happy with the K...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(n_components=10, random_state=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=10, random_state=1)\n",
    "model.fit(X_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame displaying each topic (component) along with its corresponding factorization matrix based on each feature name (words minus stop words based on tf-idf vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>12</th>\n",
       "      <th>15mp</th>\n",
       "      <th>16</th>\n",
       "      <th>16209</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yuan</th>\n",
       "      <th>yummmmmy</th>\n",
       "      <th>zealots</th>\n",
       "      <th>zero</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zydrunas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.060965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045642</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.015048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.020555</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>0.086741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000        10       100      1000        12      15mp  \\\n",
       "0  0.000000  0.000334  0.060965  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000568  0.020619  0.000000  0.000317  0.000000  0.000000   \n",
       "2  0.013405  0.003114  0.001532  0.020555  0.000146  0.013405  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.004277   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.006055  0.009733  0.008719  0.000000  0.000000  0.005341   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.072837  0.000000  0.000000   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.003648  0.001603  0.004748  0.000000  0.000000  0.000000   \n",
       "9  0.000000  0.000000  0.012442  0.009260  0.000000  0.000000  0.002801   \n",
       "\n",
       "         16     16209        17  ...      york   youtube        yr      yuan  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.045642  0.000649   \n",
       "1  0.000735  0.015048  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000120  0.000329  0.004277  ...  0.041890  0.000000  0.000000  0.000030   \n",
       "4  0.001417  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.003675  0.000000  0.005341  ...  0.006504  0.009484  0.000000  0.007779   \n",
       "6  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.000993  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9  0.000000  0.000000  0.002801  ...  0.000000  0.002308  0.000000  0.001046   \n",
       "\n",
       "   yummmmmy   zealots      zero      zomg      zoom  zydrunas  \n",
       "0  0.000000  0.000000  0.000552  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.001692  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.003183  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.008273  0.000000  \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.028355  0.086741  \n",
       "8  0.001179  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9  0.003723  0.010034  0.002172  0.030807  0.012222  0.000000  \n",
       "\n",
       "[10 rows x 1769 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_features_matrix = pd.DataFrame(model.components_, columns=vectorizer.get_feature_names())\n",
    "components_features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Each Topic's Most Important Words Based on NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0's top 15 words:\n",
      "night       1.336949\n",
      "museum      1.244221\n",
      "watching    0.343952\n",
      "saw         0.268381\n",
      "loved       0.258900\n",
      "good        0.228320\n",
      "movie       0.221372\n",
      "pretty      0.204842\n",
      "trek        0.196196\n",
      "star        0.192996\n",
      "awesome     0.189122\n",
      "movies      0.188471\n",
      "new         0.182788\n",
      "went        0.156321\n",
      "old         0.134661\n",
      "Name: 0, dtype: float64\n",
      "Topic 1's top 15 words:\n",
      "time        0.932259\n",
      "warner      0.801095\n",
      "cable       0.334539\n",
      "internet    0.232703\n",
      "suck        0.151193\n",
      "rt          0.106580\n",
      "damn        0.105330\n",
      "phone       0.104910\n",
      "problems    0.100967\n",
      "hd          0.098793\n",
      "line        0.096825\n",
      "slogan      0.092082\n",
      "day         0.090521\n",
      "worst       0.088042\n",
      "epic        0.081569\n",
      "Name: 1, dtype: float64\n",
      "Topic 2's top 15 words:\n",
      "twitter    1.021786\n",
      "api        0.947841\n",
      "playing    0.246436\n",
      "testing    0.234403\n",
      "use        0.155396\n",
      "hello      0.144731\n",
      "curl       0.117297\n",
      "java       0.117297\n",
      "loves      0.100893\n",
      "curses     0.098083\n",
      "limit      0.098083\n",
      "remote     0.087445\n",
      "update     0.083372\n",
      "tweets     0.082851\n",
      "arg        0.082035\n",
      "Name: 2, dtype: float64\n",
      "Topic 3's top 15 words:\n",
      "love       1.259970\n",
      "kindle2    0.430685\n",
      "reading    0.165300\n",
      "came       0.158132\n",
      "50d        0.149752\n",
      "obama      0.149167\n",
      "danny      0.135445\n",
      "makes      0.132037\n",
      "jokes      0.129785\n",
      "gokey      0.127422\n",
      "place      0.120467\n",
      "canon      0.114363\n",
      "new        0.113887\n",
      "40d        0.097463\n",
      "toy        0.090806\n",
      "Name: 3, dtype: float64\n",
      "Topic 4's top 15 words:\n",
      "dentist      1.007222\n",
      "hate         0.669771\n",
      "going        0.588970\n",
      "trek         0.233096\n",
      "star         0.231277\n",
      "later        0.170916\n",
      "effing       0.161429\n",
      "exam         0.138223\n",
      "pet          0.132424\n",
      "tomorrow     0.121882\n",
      "appt         0.114032\n",
      "great        0.110786\n",
      "anyways      0.110241\n",
      "invented     0.110241\n",
      "expensive    0.109320\n",
      "Name: 4, dtype: float64\n",
      "Topic 5's top 15 words:\n",
      "gladwell       0.558071\n",
      "malcolm        0.558071\n",
      "jquery         0.502306\n",
      "new            0.460891\n",
      "book           0.422566\n",
      "rt             0.288891\n",
      "goodby         0.191598\n",
      "silverstein    0.191598\n",
      "great          0.185279\n",
      "site           0.177813\n",
      "review         0.159983\n",
      "recommend      0.158656\n",
      "highly         0.141826\n",
      "learning       0.140455\n",
      "loving         0.119522\n",
      "Name: 5, dtype: float64\n",
      "Topic 6's top 15 words:\n",
      "francisco      0.929724\n",
      "san            0.929724\n",
      "breakers       0.383803\n",
      "bay            0.231750\n",
      "today          0.225503\n",
      "heading        0.188726\n",
      "suggestions    0.170795\n",
      "ca             0.167221\n",
      "landed         0.163880\n",
      "bonjour        0.124636\n",
      "hurts          0.118760\n",
      "hours          0.091449\n",
      "girl           0.084391\n",
      "mmmmmfamily    0.083930\n",
      "wonderful      0.083930\n",
      "Name: 6, dtype: float64\n",
      "Topic 7's top 15 words:\n",
      "lebron       1.271788\n",
      "best         0.560896\n",
      "good         0.517903\n",
      "kobe         0.442276\n",
      "world        0.240777\n",
      "nba          0.188490\n",
      "boss         0.173063\n",
      "vote         0.149063\n",
      "beast        0.139583\n",
      "bt           0.129605\n",
      "like         0.127784\n",
      "playoffs     0.125344\n",
      "murdering    0.124765\n",
      "shit         0.109135\n",
      "gm           0.106702\n",
      "Name: 7, dtype: float64\n",
      "Topic 8's top 15 words:\n",
      "safeway     1.111060\n",
      "dad         0.203395\n",
      "don         0.203252\n",
      "coupons     0.169862\n",
      "mobile      0.169862\n",
      "like        0.138532\n",
      "jake        0.121876\n",
      "tonight     0.109538\n",
      "waiting     0.108874\n",
      "line        0.106101\n",
      "staples     0.104604\n",
      "picking     0.100169\n",
      "going       0.096302\n",
      "offering    0.093337\n",
      "roll        0.090836\n",
      "Name: 8, dtype: float64\n",
      "Topic 9's top 15 words:\n",
      "just       0.720875\n",
      "got        0.539092\n",
      "nike       0.422675\n",
      "amp        0.267116\n",
      "google     0.254701\n",
      "g2         0.217643\n",
      "free       0.179842\n",
      "android    0.155824\n",
      "office     0.144301\n",
      "50d        0.137982\n",
      "new        0.129754\n",
      "phone      0.100474\n",
      "insects    0.100432\n",
      "iphone     0.098247\n",
      "using      0.097212\n",
      "Name: 9, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for component in range(components_features_matrix.shape[0]):\n",
    "    print(\"Topic {}'s top 15 words:\".format(component))\n",
    "    words = components_features_matrix.iloc[component].nlargest(15)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) And now we repeat with Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(n_components=10, random_state=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=10, random_state=1)\n",
    "model.fit(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_features_matrix = pd.DataFrame(model.components_, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0's top 15 words:\n",
      "time        2.555006\n",
      "warner      2.096993\n",
      "cable       0.674406\n",
      "internet    0.403957\n",
      "watch       0.208149\n",
      "phone       0.175457\n",
      "hd          0.166548\n",
      "suck        0.165790\n",
      "damn        0.161135\n",
      "worst       0.159091\n",
      "slogan      0.155378\n",
      "rt          0.154266\n",
      "today       0.153406\n",
      "want        0.145353\n",
      "com         0.141308\n",
      "Name: 0, dtype: float64\n",
      "Topic 1's top 15 words:\n",
      "night       2.588311\n",
      "museum      2.042813\n",
      "star        0.445398\n",
      "trek        0.439411\n",
      "movie       0.421398\n",
      "saw         0.417217\n",
      "awesome     0.270109\n",
      "old         0.261911\n",
      "pretty      0.232758\n",
      "went        0.232325\n",
      "seeing      0.230646\n",
      "going       0.228613\n",
      "movies      0.220252\n",
      "today       0.210538\n",
      "watching    0.200677\n",
      "Name: 1, dtype: float64\n",
      "Topic 2's top 15 words:\n",
      "love       2.646885\n",
      "kindle2    0.369236\n",
      "50d        0.288313\n",
      "40d        0.274481\n",
      "place      0.242141\n",
      "getting    0.198128\n",
      "model      0.196092\n",
      "ooooh      0.196092\n",
      "got        0.186729\n",
      "lol        0.181222\n",
      "ve         0.179898\n",
      "canon      0.146639\n",
      "jquery     0.146229\n",
      "d90        0.139771\n",
      "toy        0.136747\n",
      "Name: 2, dtype: float64\n",
      "Topic 3's top 15 words:\n",
      "just         2.517967\n",
      "got          1.021508\n",
      "google       0.282994\n",
      "hi           0.258258\n",
      "stanford     0.253834\n",
      "obama        0.245136\n",
      "really       0.199377\n",
      "talk         0.188282\n",
      "saying       0.180678\n",
      "dinner       0.180306\n",
      "using        0.171695\n",
      "nike         0.168859\n",
      "g2           0.159345\n",
      "mcdonalds    0.155511\n",
      "insects      0.148570\n",
      "Name: 3, dtype: float64\n",
      "Topic 4's top 15 words:\n",
      "good        2.450608\n",
      "lebron      0.650176\n",
      "kobe        0.470981\n",
      "like        0.427419\n",
      "google      0.326384\n",
      "car         0.277552\n",
      "day         0.229858\n",
      "nba         0.216458\n",
      "looking     0.196668\n",
      "said        0.195209\n",
      "probably    0.170415\n",
      "alot        0.167744\n",
      "greater     0.167744\n",
      "players     0.167744\n",
      "exam        0.150565\n",
      "Name: 4, dtype: float64\n",
      "Topic 5's top 15 words:\n",
      "new         2.629882\n",
      "nike        0.854489\n",
      "canon       0.841281\n",
      "brand       0.479537\n",
      "eos         0.460507\n",
      "blog        0.459946\n",
      "post        0.346977\n",
      "50d         0.339838\n",
      "gladwell    0.311228\n",
      "malcolm     0.311228\n",
      "best        0.308785\n",
      "site        0.253437\n",
      "web         0.234282\n",
      "lebron      0.232668\n",
      "15mp        0.230253\n",
      "Name: 5, dtype: float64\n",
      "Topic 6's top 15 words:\n",
      "amp            1.899516\n",
      "great          0.894937\n",
      "bobby          0.437041\n",
      "today          0.406415\n",
      "flay           0.371107\n",
      "book           0.326326\n",
      "kindle2        0.254222\n",
      "buffet         0.227496\n",
      "warren         0.227496\n",
      "food           0.199591\n",
      "weekend        0.193181\n",
      "goodby         0.185812\n",
      "silverstein    0.185812\n",
      "iphone         0.185405\n",
      "tomorrow       0.174551\n",
      "Name: 6, dtype: float64\n",
      "Topic 7's top 15 words:\n",
      "hate        2.290450\n",
      "latex       0.781977\n",
      "dentist     0.538152\n",
      "come        0.349937\n",
      "pages       0.309256\n",
      "word        0.304548\n",
      "kill        0.300858\n",
      "note        0.300858\n",
      "texn3rds    0.300858\n",
      "said        0.285589\n",
      "lt          0.173935\n",
      "looking     0.156858\n",
      "watch       0.148711\n",
      "aig         0.135512\n",
      "safeway     0.135278\n",
      "Name: 7, dtype: float64\n",
      "Topic 8's top 15 words:\n",
      "twitter     1.542940\n",
      "api         1.478346\n",
      "playing     0.321008\n",
      "like        0.207292\n",
      "tweets      0.199006\n",
      "jquery      0.192276\n",
      "class       0.166116\n",
      "code        0.161649\n",
      "fun         0.157183\n",
      "testing     0.156837\n",
      "need        0.155312\n",
      "friend      0.153505\n",
      "generate    0.148516\n",
      "results     0.148516\n",
      "sounds      0.148516\n",
      "Name: 8, dtype: float64\n",
      "Topic 9's top 15 words:\n",
      "gm             1.583998\n",
      "rt             1.115748\n",
      "day            0.389775\n",
      "announcment    0.250418\n",
      "expects        0.250418\n",
      "hummer         0.250418\n",
      "sale           0.250418\n",
      "says           0.250418\n",
      "sad            0.246389\n",
      "buy            0.228649\n",
      "jquery         0.221875\n",
      "thing          0.213090\n",
      "taking         0.190002\n",
      "know           0.180862\n",
      "life           0.171414\n",
      "Name: 9, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for component in range(components_features_matrix.shape[0]):\n",
    "    print(\"Topic {}'s top 15 words:\".format(component))\n",
    "    words = components_features_matrix.iloc[component].nlargest(15)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) tf-idf with regularization\n",
    "### regularation terms (W and H), factorization matrices) are multiplied with a constant, l1 penality is applied as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, l1_ratio=0.1, n_components=10, random_state=1, shuffle=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=10, random_state=1, alpha=0.1, l1_ratio=0.1, shuffle=True)\n",
    "model.fit(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_features_matrix = pd.DataFrame(model.components_, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0's top 15 words:\n",
      "night       1.013857\n",
      "museum      0.947391\n",
      "watching    0.257489\n",
      "saw         0.200455\n",
      "loved       0.195407\n",
      "good        0.179517\n",
      "movie       0.164187\n",
      "pretty      0.151902\n",
      "trek        0.147900\n",
      "star        0.145104\n",
      "awesome     0.139071\n",
      "new         0.138826\n",
      "movies      0.137963\n",
      "went        0.114509\n",
      "giggling    0.098210\n",
      "Name: 0, dtype: float64\n",
      "Topic 1's top 15 words:\n",
      "time        1.013948\n",
      "warner      0.872050\n",
      "cable       0.362346\n",
      "internet    0.250236\n",
      "suck        0.161887\n",
      "rt          0.111968\n",
      "damn        0.110561\n",
      "phone       0.109403\n",
      "problems    0.106761\n",
      "hd          0.103824\n",
      "line        0.102327\n",
      "slogan      0.097575\n",
      "worst       0.091124\n",
      "day         0.089710\n",
      "epic        0.085929\n",
      "Name: 1, dtype: float64\n",
      "Topic 2's top 15 words:\n",
      "twitter    1.012066\n",
      "api        0.941841\n",
      "playing    0.240927\n",
      "testing    0.231024\n",
      "use        0.147759\n",
      "hello      0.141075\n",
      "curl       0.113186\n",
      "java       0.113186\n",
      "loves      0.095805\n",
      "curses     0.093674\n",
      "limit      0.093674\n",
      "remote     0.082977\n",
      "update     0.078442\n",
      "arg        0.077201\n",
      "tweets     0.073862\n",
      "Name: 2, dtype: float64\n",
      "Topic 3's top 15 words:\n",
      "love       1.207457\n",
      "kindle2    0.391711\n",
      "reading    0.150577\n",
      "came       0.148119\n",
      "50d        0.136447\n",
      "danny      0.118976\n",
      "makes      0.118490\n",
      "jokes      0.113796\n",
      "new        0.113750\n",
      "gokey      0.112951\n",
      "obama      0.110621\n",
      "place      0.104653\n",
      "canon      0.102344\n",
      "40d        0.087389\n",
      "toy        0.084434\n",
      "Name: 3, dtype: float64\n",
      "Topic 4's top 15 words:\n",
      "dentist      0.965425\n",
      "hate         0.623057\n",
      "going        0.551113\n",
      "trek         0.205831\n",
      "star         0.203046\n",
      "later        0.158839\n",
      "effing       0.152182\n",
      "pet          0.124562\n",
      "exam         0.107043\n",
      "appt         0.103702\n",
      "tomorrow     0.101834\n",
      "anyways      0.101667\n",
      "invented     0.101667\n",
      "expensive    0.099698\n",
      "morning      0.091916\n",
      "Name: 4, dtype: float64\n",
      "Topic 5's top 15 words:\n",
      "gladwell       0.624661\n",
      "malcolm        0.624661\n",
      "new            0.451668\n",
      "jquery         0.450794\n",
      "book           0.418606\n",
      "rt             0.262346\n",
      "recommend      0.174041\n",
      "goodby         0.168416\n",
      "silverstein    0.168416\n",
      "great          0.162537\n",
      "site           0.161664\n",
      "highly         0.159402\n",
      "review         0.148152\n",
      "tipping        0.130503\n",
      "point          0.124085\n",
      "Name: 5, dtype: float64\n",
      "Topic 6's top 15 words:\n",
      "francisco      0.862556\n",
      "san            0.862556\n",
      "breakers       0.353651\n",
      "bay            0.209338\n",
      "today          0.178135\n",
      "heading        0.172478\n",
      "suggestions    0.152138\n",
      "landed         0.149188\n",
      "ca             0.148010\n",
      "bonjour        0.111817\n",
      "hurts          0.105658\n",
      "hours          0.072767\n",
      "mmmmmfamily    0.072010\n",
      "wonderful      0.072010\n",
      "girl           0.070079\n",
      "Name: 6, dtype: float64\n",
      "Topic 7's top 15 words:\n",
      "lebron       1.082043\n",
      "best         0.473532\n",
      "kobe         0.366802\n",
      "good         0.347551\n",
      "world        0.194860\n",
      "nba          0.153288\n",
      "boss         0.146024\n",
      "beast        0.113530\n",
      "vote         0.113015\n",
      "murdering    0.102451\n",
      "bt           0.102085\n",
      "playoffs     0.102049\n",
      "like         0.088112\n",
      "shit         0.084704\n",
      "duo          0.069647\n",
      "Name: 7, dtype: float64\n",
      "Topic 8's top 15 words:\n",
      "safeway     1.190385\n",
      "dad         0.211905\n",
      "don         0.211150\n",
      "coupons     0.177611\n",
      "mobile      0.177611\n",
      "like        0.128676\n",
      "jake        0.128306\n",
      "waiting     0.113068\n",
      "staples     0.108341\n",
      "line        0.107775\n",
      "picking     0.102602\n",
      "tonight     0.098172\n",
      "offering    0.095953\n",
      "going       0.092887\n",
      "dead        0.091672\n",
      "Name: 8, dtype: float64\n",
      "Topic 9's top 15 words:\n",
      "just          0.799585\n",
      "got           0.621016\n",
      "nike          0.386816\n",
      "google        0.275295\n",
      "amp           0.252177\n",
      "g2            0.241527\n",
      "free          0.203639\n",
      "android       0.175649\n",
      "office        0.169189\n",
      "50d           0.161847\n",
      "new           0.142440\n",
      "good          0.117323\n",
      "phone         0.107249\n",
      "insects       0.103222\n",
      "conference    0.098330\n",
      "Name: 9, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for component in range(components_features_matrix.shape[0]):\n",
    "    print(\"Topic {}'s top 15 words:\".format(component))\n",
    "    words = components_features_matrix.iloc[component].nlargest(15)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Count Vectorization with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, l1_ratio=0.1, n_components=10, random_state=1, shuffle=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=10, random_state=1, alpha=0.1, l1_ratio=0.1, shuffle=True)\n",
    "model.fit(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_features_matrix = pd.DataFrame(model.components_, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0's top 15 words:\n",
      "time        2.289942\n",
      "warner      1.879547\n",
      "cable       0.603994\n",
      "internet    0.361816\n",
      "watch       0.186067\n",
      "phone       0.156519\n",
      "hd          0.148666\n",
      "suck        0.147885\n",
      "damn        0.143513\n",
      "worst       0.141829\n",
      "rt          0.140019\n",
      "slogan      0.138804\n",
      "today       0.137195\n",
      "want        0.129482\n",
      "com         0.125577\n",
      "Name: 0, dtype: float64\n",
      "Topic 1's top 15 words:\n",
      "night       2.132800\n",
      "museum      1.684180\n",
      "star        0.365595\n",
      "trek        0.360868\n",
      "movie       0.346587\n",
      "saw         0.343294\n",
      "awesome     0.220899\n",
      "old         0.214398\n",
      "pretty      0.190938\n",
      "went        0.190493\n",
      "seeing      0.189211\n",
      "going       0.186195\n",
      "movies      0.180739\n",
      "today       0.171784\n",
      "watching    0.164036\n",
      "Name: 1, dtype: float64\n",
      "Topic 2's top 15 words:\n",
      "love       2.569669\n",
      "kindle2    0.356354\n",
      "50d        0.279409\n",
      "40d        0.265280\n",
      "place      0.233999\n",
      "getting    0.191362\n",
      "model      0.189466\n",
      "ooooh      0.189466\n",
      "got        0.179888\n",
      "lol        0.173431\n",
      "ve         0.173266\n",
      "canon      0.142471\n",
      "jquery     0.139843\n",
      "d90        0.134221\n",
      "toy        0.132105\n",
      "Name: 2, dtype: float64\n",
      "Topic 3's top 15 words:\n",
      "just         2.308802\n",
      "got          0.936546\n",
      "google       0.257643\n",
      "hi           0.235847\n",
      "stanford     0.229864\n",
      "obama        0.222059\n",
      "really       0.181133\n",
      "talk         0.171357\n",
      "saying       0.164552\n",
      "dinner       0.164412\n",
      "using        0.154963\n",
      "nike         0.152316\n",
      "g2           0.143672\n",
      "mcdonalds    0.140162\n",
      "insects      0.134303\n",
      "Name: 3, dtype: float64\n",
      "Topic 4's top 15 words:\n",
      "good        2.266731\n",
      "lebron      0.595348\n",
      "kobe        0.434169\n",
      "like        0.393485\n",
      "google      0.298114\n",
      "car         0.255604\n",
      "day         0.211722\n",
      "nba         0.198466\n",
      "looking     0.180899\n",
      "said        0.180027\n",
      "probably    0.156394\n",
      "alot        0.153977\n",
      "greater     0.153977\n",
      "players     0.153977\n",
      "exam        0.136554\n",
      "Name: 4, dtype: float64\n",
      "Topic 5's top 15 words:\n",
      "new         2.111400\n",
      "canon       0.678337\n",
      "nike        0.675495\n",
      "brand       0.385750\n",
      "eos         0.370835\n",
      "blog        0.365032\n",
      "post        0.276629\n",
      "50d         0.273960\n",
      "gladwell    0.247397\n",
      "malcolm     0.247397\n",
      "best        0.242386\n",
      "site        0.203098\n",
      "web         0.187870\n",
      "15mp        0.184725\n",
      "17          0.184725\n",
      "Name: 5, dtype: float64\n",
      "Topic 6's top 15 words:\n",
      "amp            1.882729\n",
      "great          0.891800\n",
      "bobby          0.432654\n",
      "today          0.402436\n",
      "flay           0.367358\n",
      "book           0.332117\n",
      "kindle2        0.250646\n",
      "buffet         0.228311\n",
      "warren         0.228311\n",
      "food           0.196081\n",
      "weekend        0.189888\n",
      "goodby         0.182040\n",
      "silverstein    0.182040\n",
      "iphone         0.180397\n",
      "tomorrow       0.171716\n",
      "Name: 6, dtype: float64\n",
      "Topic 7's top 15 words:\n",
      "hate        2.124715\n",
      "latex       0.722590\n",
      "dentist     0.491053\n",
      "come        0.322399\n",
      "pages       0.285919\n",
      "word        0.282075\n",
      "kill        0.278648\n",
      "note        0.278648\n",
      "texn3rds    0.278648\n",
      "said        0.264789\n",
      "lt          0.154764\n",
      "looking     0.143326\n",
      "watch       0.135872\n",
      "aig         0.122660\n",
      "soooo       0.120127\n",
      "Name: 7, dtype: float64\n",
      "Topic 8's top 15 words:\n",
      "twitter     1.683820\n",
      "api         1.613807\n",
      "playing     0.349310\n",
      "like        0.218586\n",
      "tweets      0.214480\n",
      "jquery      0.195140\n",
      "class       0.177891\n",
      "code        0.174085\n",
      "testing     0.169979\n",
      "fun         0.169524\n",
      "need        0.167046\n",
      "friend      0.165851\n",
      "generate    0.160831\n",
      "results     0.160831\n",
      "sounds      0.160831\n",
      "Name: 8, dtype: float64\n",
      "Topic 9's top 15 words:\n",
      "gm             1.633426\n",
      "rt             1.122435\n",
      "day            0.389720\n",
      "announcment    0.259613\n",
      "expects        0.259613\n",
      "hummer         0.259613\n",
      "sale           0.259613\n",
      "says           0.259613\n",
      "sad            0.251717\n",
      "buy            0.234945\n",
      "thing          0.217823\n",
      "taking         0.193357\n",
      "jquery         0.187586\n",
      "know           0.184558\n",
      "life           0.173942\n",
      "Name: 9, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for component in range(components_features_matrix.shape[0]):\n",
    "    print(\"Topic {}'s top 15 words:\".format(component))\n",
    "    words = components_features_matrix.iloc[component].nlargest(15)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "964f1a1cfa1089e75d896b4573a388abc4dba8c844d4d647a221b6b672ac490a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
